{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lexicon-based approaches"
      ],
      "metadata": {
        "id": "UnB7-sdBeLCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pattern.nl"
      ],
      "metadata": {
        "id": "QULvWhfbeWzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library\n",
        "!pip install pattern\n",
        "!pip install nltk\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "fv3Yca81eZFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e45f8dc-bd99-4c41-d297-c6baa872c2b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pattern in /usr/local/lib/python3.10/dist-packages (3.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pattern) (0.18.3)\n",
            "Requirement already satisfied: backports.csv in /usr/local/lib/python3.10/dist-packages (from pattern) (1.0.7)\n",
            "Requirement already satisfied: mysqlclient in /usr/local/lib/python3.10/dist-packages (from pattern) (2.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from pattern) (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pattern) (4.9.4)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.10/dist-packages (from pattern) (6.0.11)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from pattern) (20231228)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pattern) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pattern) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pattern) (3.8.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from pattern) (1.1.2)\n",
            "Requirement already satisfied: cherrypy in /usr/local/lib/python3.10/dist-packages (from pattern) (18.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pattern) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->pattern) (2.5)\n",
            "Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (10.0.1)\n",
            "Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (3.2.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (10.1.0)\n",
            "Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (3.0.post1)\n",
            "Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (5.0.1)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser->pattern) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pattern) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pattern) (42.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->pattern) (4.12.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (2024.6.2)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.10/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (4.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.16.0)\n",
            "Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.10/dist-packages (from portend>=2.1.1->cherrypy->pattern) (5.6.0)\n",
            "Requirement already satisfied: jaraco.text in /usr/local/lib/python3.10/dist-packages (from jaraco.collections->cherrypy->pattern) (3.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zc.lockfile->cherrypy->pattern) (67.7.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.22)\n",
            "Requirement already satisfied: jaraco.context>=4.1 in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (5.3.0)\n",
            "Requirement already satisfied: autocommand in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (2.2.2)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (7.0.0)\n",
            "Requirement already satisfied: backports.tarfile in /usr/local/lib/python3.10/dist-packages (from jaraco.context>=4.1->jaraco.text->jaraco.collections->cherrypy->pattern) (1.2.0)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (2.7.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (2.18.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pattern.nl import sentiment\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "# Download NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# List of Dutch stop words\n",
        "dutch_stopwords = set(stopwords.words('dutch'))\n",
        "\n",
        "# Preprocess text data\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    tokens = [word for word in tokens if word not in dutch_stopwords]\n",
        "    # Join tokens back into a single string\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "# Replace the numerical labels with the sentiment categories\n",
        "def map_labels(label):\n",
        "    if label == 0:\n",
        "        return \"negative\"\n",
        "    elif label == 1:\n",
        "        return \"neutral\"\n",
        "    elif label == 2:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# Create function to perform sentiment analysis and generate classification report and confusion matrix\n",
        "def analyze_sentiment_and_report(dataset):\n",
        "    # Preprocess text in the dataset\n",
        "    dataset[\"preprocessed_text\"] = dataset[\"text\"].apply(preprocess_text)\n",
        "\n",
        "    predicted_labels = []\n",
        "    for text in dataset[\"preprocessed_text\"]:\n",
        "        polarity, _ = sentiment(text)\n",
        "        predicted_label = \"positive\" if polarity > 0 else \"negative\" if polarity < 0 else \"neutral\" # Threshold for neutral is 0\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # Map numerical ground truth labels to sentiment categories\n",
        "    ground_truth_labels = dataset[\"labels\"].apply(map_labels)\n",
        "\n",
        "    # Create classification report\n",
        "    report = classification_report(ground_truth_labels, predicted_labels)\n",
        "\n",
        "    # Create confusion matrix\n",
        "    conf_matrix = confusion_matrix(ground_truth_labels, predicted_labels, labels=[\"negative\", \"neutral\", \"positive\"])\n",
        "\n",
        "    return report, conf_matrix\n",
        "\n",
        "# Paths to datasets\n",
        "dataset_paths = [\"1960s_gas.csv\", \"1970s_gas.csv\",\n",
        "                 \"1980s_gas.csv\", \"1990s_gas.csv\"]\n",
        "\n",
        "# Iterate over each dataset path in the list\n",
        "for dataset_path in dataset_paths:\n",
        "    dataset_name = dataset_path.split(\".\")[0]\n",
        "    dataset = pd.read_csv(dataset_path)\n",
        "    print(f\"Classification Report for {dataset_name}:\")\n",
        "    report, conf_matrix = analyze_sentiment_and_report(dataset)\n",
        "    print(report)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    print(\"-\" * 50)  # Separating reports\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwVNU2oytqgG",
        "outputId": "e083d35f-7ba4-4d84-a3a0-22f020dd034a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for 1960s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.24      0.18      0.21        82\n",
            "     neutral       0.55      0.05      0.08       131\n",
            "    positive       0.53      0.86      0.66       220\n",
            "\n",
            "    accuracy                           0.49       433\n",
            "   macro avg       0.44      0.36      0.32       433\n",
            "weighted avg       0.48      0.49      0.40       433\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 15   0  67]\n",
            " [ 22   6 103]\n",
            " [ 25   5 190]]\n",
            "--------------------------------------------------\n",
            "Classification Report for 1970s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.33      0.21      0.26        19\n",
            "     neutral       0.00      0.00      0.00        22\n",
            "    positive       0.58      0.87      0.70        55\n",
            "\n",
            "    accuracy                           0.54        96\n",
            "   macro avg       0.30      0.36      0.32        96\n",
            "weighted avg       0.40      0.54      0.45        96\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 4  0 15]\n",
            " [ 2  0 20]\n",
            " [ 6  1 48]]\n",
            "--------------------------------------------------\n",
            "Classification Report for 1980s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.45      0.15      0.22        88\n",
            "     neutral       0.33      0.02      0.04        43\n",
            "    positive       0.41      0.87      0.55        86\n",
            "\n",
            "    accuracy                           0.41       217\n",
            "   macro avg       0.40      0.35      0.27       217\n",
            "weighted avg       0.41      0.41      0.32       217\n",
            "\n",
            "Confusion Matrix:\n",
            "[[13  1 74]\n",
            " [ 6  1 36]\n",
            " [10  1 75]]\n",
            "--------------------------------------------------\n",
            "Classification Report for 1990s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.44      0.32      0.37        25\n",
            "     neutral       0.00      0.00      0.00        14\n",
            "    positive       0.18      0.46      0.26        13\n",
            "\n",
            "    accuracy                           0.27        52\n",
            "   macro avg       0.21      0.26      0.21        52\n",
            "weighted avg       0.26      0.27      0.24        52\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8  0 17]\n",
            " [ 4  0 10]\n",
            " [ 6  1  6]]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LUPJE"
      ],
      "metadata": {
        "id": "uPGJ37I_73Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMC3xRWbvgcu",
        "outputId": "4daba5f8-d5e3-4c41-ed4f-68eb72bffb0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Download NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Replace the numerical labels with the sentiment categories\n",
        "def map_labels(label):\n",
        "    if label == 0:\n",
        "        return \"negative\"\n",
        "    elif label == 1:\n",
        "        return \"neutral\"\n",
        "    elif label == 2:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# List of Dutch stop words\n",
        "dutch_stopwords = set(stopwords.words('dutch'))\n",
        "\n",
        "# Preprocess text data\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    tokens = [word for word in tokens if word not in dutch_stopwords]\n",
        "    # Join tokens back into a single string\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "# Read the text file into a DataFrame, skipping lines with incorrect formatting\n",
        "words_sentiment_df = pd.DataFrame(columns=[\"word\", \"sentiment_score\"])\n",
        "\n",
        "with open(\"LUPJE.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            word, sentiment_score = line.strip().split(\"\\t\")\n",
        "            words_sentiment_df = pd.concat([words_sentiment_df, pd.DataFrame({\"word\": [word], \"sentiment_score\": [sentiment_score]})])\n",
        "        except ValueError:\n",
        "            print(f\"Skipping line with incorrect formatting: {line.strip()}\")\n",
        "\n",
        "# Convert sentiment scores to numeric type\n",
        "words_sentiment_df[\"sentiment_score\"] = pd.to_numeric(words_sentiment_df[\"sentiment_score\"])\n",
        "\n",
        "# Function that performs the sentiment analysis\n",
        "def analyze_sentiment(text):\n",
        "    # Preprocess the text\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "    # Tokenize the text\n",
        "    tokens = preprocessed_text.split()\n",
        "    sentiment_score = 0\n",
        "\n",
        "    # Calculate sentiment score based on words in the text\n",
        "    for token in tokens:\n",
        "        if token in words_sentiment_df[\"word\"].values:\n",
        "            sentiment_score += words_sentiment_df.loc[words_sentiment_df[\"word\"] == token, \"sentiment_score\"].values[0]\n",
        "\n",
        "    # Determine sentiment label based on sentiment score\n",
        "    if sentiment_score > 0:\n",
        "        return \"positive\"\n",
        "    elif sentiment_score < 0:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "# Perform sentiment analysis on the dataset\n",
        "def perform_sentiment_analysis(dataset):\n",
        "    # Map numerical labels to sentiment categories\n",
        "    dataset[\"true_sentiment\"] = dataset[\"labels\"].map({0: \"negative\", 1: \"neutral\", 2: \"positive\"})\n",
        "\n",
        "    # Apply sentiment analysis to the text column\n",
        "    dataset[\"predicted_sentiment\"] = dataset[\"text\"].apply(analyze_sentiment)\n",
        "    return dataset\n",
        "\n",
        "# Function that performs sentiment analysis and generates a classification report for each dataset\n",
        "def generate_classification_report(dataset):\n",
        "    result_dataset = perform_sentiment_analysis(dataset)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(result_dataset[\"true_sentiment\"], result_dataset[\"predicted_sentiment\"])\n",
        "\n",
        "    return report\n",
        "\n",
        "# Paths to datasets\n",
        "dataset_paths = [\"1960s_gas.csv\", \"1970s_gas.csv\",\n",
        "                 \"1980s_gas.csv\", \"1990s_gas.csv\"]\n",
        "\n",
        "# Iterate over each dataset path in the list\n",
        "for dataset_path in dataset_paths:\n",
        "    dataset_name = dataset_path.split(\".\")[0]\n",
        "    your_dataset = pd.read_csv(dataset_path)\n",
        "    print(f\"Classification Report for {dataset_name}:\")\n",
        "    report = generate_classification_report(your_dataset)\n",
        "    print(report)\n",
        "    print(\"-\" * 50)  # Separating reports\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CyUFpOHbdEH",
        "outputId": "3ae62af0-0b73-4e42-ab79-36a229b2d31c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for 1960s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.21      0.26      0.23        82\n",
            "     neutral       0.42      0.08      0.14       131\n",
            "    positive       0.53      0.74      0.62       220\n",
            "\n",
            "    accuracy                           0.45       433\n",
            "   macro avg       0.39      0.36      0.33       433\n",
            "weighted avg       0.44      0.45      0.40       433\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for 1970s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.14      0.21      0.17        19\n",
            "     neutral       0.00      0.00      0.00        22\n",
            "    positive       0.50      0.60      0.55        55\n",
            "\n",
            "    accuracy                           0.39        96\n",
            "   macro avg       0.21      0.27      0.24        96\n",
            "weighted avg       0.31      0.39      0.35        96\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for 1980s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.40      0.24      0.30        88\n",
            "     neutral       0.00      0.00      0.00        43\n",
            "    positive       0.42      0.77      0.54        86\n",
            "\n",
            "    accuracy                           0.40       217\n",
            "   macro avg       0.27      0.34      0.28       217\n",
            "weighted avg       0.33      0.40      0.34       217\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for 1990s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.32      0.24      0.27        25\n",
            "     neutral       0.25      0.07      0.11        14\n",
            "    positive       0.14      0.31      0.19        13\n",
            "\n",
            "    accuracy                           0.21        52\n",
            "   macro avg       0.23      0.21      0.19        52\n",
            "weighted avg       0.25      0.21      0.21        52\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}