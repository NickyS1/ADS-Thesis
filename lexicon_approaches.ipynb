{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lexicon-based approaches"
      ],
      "metadata": {
        "id": "UnB7-sdBeLCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pattern.nl"
      ],
      "metadata": {
        "id": "QULvWhfbeWzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library\n",
        "!pip install pattern"
      ],
      "metadata": {
        "id": "fv3Yca81eZFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58211708-19a1-45ff-878e-35ca295d7f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pattern) (0.18.3)\n",
            "Collecting backports.csv (from pattern)\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient (from pattern)\n",
            "  Downloading mysqlclient-2.2.4.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from pattern) (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pattern) (4.9.4)\n",
            "Collecting feedparser (from pattern)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six (from pattern)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pattern) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pattern) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pattern) (3.8.1)\n",
            "Collecting python-docx (from pattern)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cherrypy (from pattern)\n",
            "  Downloading CherryPy-18.10.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.8/349.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pattern) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->pattern) (2.5)\n",
            "Collecting cheroot>=8.2.1 (from cherrypy->pattern)\n",
            "  Downloading cheroot-10.0.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portend>=2.1.1 (from cherrypy->pattern)\n",
            "  Downloading portend-3.2.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from cherrypy->pattern) (10.1.0)\n",
            "Collecting zc.lockfile (from cherrypy->pattern)\n",
            "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
            "Collecting jaraco.collections (from cherrypy->pattern)\n",
            "  Downloading jaraco.collections-5.0.1-py3-none-any.whl (10 kB)\n",
            "Collecting sgmllib3k (from feedparser->pattern)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->pattern) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pattern) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pattern) (42.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->pattern) (4.12.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pattern) (2024.6.2)\n",
            "Collecting jaraco.functools (from cheroot>=8.2.1->cherrypy->pattern)\n",
            "  Downloading jaraco.functools-4.0.1-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.16.0)\n",
            "Collecting tempora>=1.8 (from portend>=2.1.1->cherrypy->pattern)\n",
            "  Downloading tempora-5.6.0-py3-none-any.whl (13 kB)\n",
            "Collecting jaraco.text (from jaraco.collections->cherrypy->pattern)\n",
            "  Downloading jaraco.text-3.12.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zc.lockfile->cherrypy->pattern) (67.7.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.22)\n",
            "Collecting jaraco.context>=4.1 (from jaraco.text->jaraco.collections->cherrypy->pattern)\n",
            "  Downloading jaraco.context-5.3.0-py3-none-any.whl (6.5 kB)\n",
            "Collecting autocommand (from jaraco.text->jaraco.collections->cherrypy->pattern)\n",
            "  Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (7.0.0)\n",
            "Collecting backports.tarfile (from jaraco.context>=4.1->jaraco.text->jaraco.collections->cherrypy->pattern)\n",
            "  Downloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (2.7.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (2.18.4)\n",
            "Building wheels for collected packages: pattern, mysqlclient, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332702 sha256=7ae504ee36d7c307e16b7d69eaccd599d3ff47cc083c5bffe433edb183c2a17f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/8f/40/fe23abd593ef60be5bfaf3e02154d3484df42aa947bbf4d499\n",
            "  Building wheel for mysqlclient (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.2.4-cp310-cp310-linux_x86_64.whl size=124740 sha256=54225a88dc217d6c5dae947e8c90f19b2942f1d6a0521593b1878ca708f8a60c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/96/ac/2a4d8cb58a4d95de1dffc3f8b0ea42e0e5b63ab97640edbda3\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=0f1b64acb0907463c5384347eae6571287d7226f8513b4cb39952fd4a8f73016\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built pattern mysqlclient sgmllib3k\n",
            "Installing collected packages: sgmllib3k, backports.csv, zc.lockfile, python-docx, mysqlclient, jaraco.functools, feedparser, backports.tarfile, autocommand, tempora, jaraco.context, cheroot, portend, pdfminer.six, jaraco.text, jaraco.collections, cherrypy, pattern\n",
            "Successfully installed autocommand-2.2.2 backports.csv-1.0.7 backports.tarfile-1.2.0 cheroot-10.0.1 cherrypy-18.10.0 feedparser-6.0.11 jaraco.collections-5.0.1 jaraco.context-5.3.0 jaraco.functools-4.0.1 jaraco.text-3.12.1 mysqlclient-2.2.4 pattern-3.6 pdfminer.six-20231228 portend-3.2.0 python-docx-1.1.2 sgmllib3k-1.0.0 tempora-5.6.0 zc.lockfile-3.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pattern.nl import sentiment\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Replace the numerical labels with the sentiment categories\n",
        "def map_labels(label):\n",
        "    if label == 0:\n",
        "        return \"negative\"\n",
        "    elif label == 1:\n",
        "        return \"neutral\"\n",
        "    elif label == 2:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# Create function to perform sentiment analysis and generate classification report and confusion matrix\n",
        "def analyze_sentiment_and_report(dataset):\n",
        "    predicted_labels = []\n",
        "    for text in dataset[\"text\"]:\n",
        "        polarity, _ = sentiment(text)\n",
        "        predicted_label = \"positive\" if polarity > 0 else \"negative\" if polarity < 0 else \"neutral\" # Threshold for neutral is 0\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # Map numerical ground truth labels to sentiment categories\n",
        "    ground_truth_labels = dataset[\"labels\"].apply(map_labels)\n",
        "\n",
        "    # Create classification report\n",
        "    report = classification_report(ground_truth_labels, predicted_labels)\n",
        "\n",
        "    # Create confusion matrix\n",
        "    conf_matrix = confusion_matrix(ground_truth_labels, predicted_labels, labels=[\"negative\", \"neutral\", \"positive\"])\n",
        "\n",
        "    return report, conf_matrix\n",
        "\n",
        "# Paths to datasets\n",
        "dataset_paths = [\"1960s_gas.csv\", \"1970s_gas.csv\",\n",
        "                 \"1980s_gas.csv\", \"1990s_gas.csv\"]\n",
        "\n",
        "# Iterate over each dataset path in the list\n",
        "for dataset_path in dataset_paths:\n",
        "    dataset_name = dataset_path.split(\".\")[0]\n",
        "    dataset = pd.read_csv(dataset_path)\n",
        "    print(f\"Classification Report for {dataset_name}:\")\n",
        "    report, conf_matrix = analyze_sentiment_and_report(dataset)\n",
        "    print(report)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    print(\"-\" * 50)  # Separating reports\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4okVnJw26cVS",
        "outputId": "85ff17f5-6af0-476f-d6c7-c54095a7907f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for 1960s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.21      0.26      0.23        82\n",
            "     neutral       0.50      0.03      0.06       131\n",
            "    positive       0.54      0.79      0.64       220\n",
            "\n",
            "    accuracy                           0.46       433\n",
            "   macro avg       0.42      0.36      0.31       433\n",
            "weighted avg       0.46      0.46      0.39       433\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 21   0  61]\n",
            " [ 37   4  90]\n",
            " [ 42   4 174]]\n",
            "--------------------------------------------------\n",
            "Classification Report for 1970s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.27      0.42      0.33        19\n",
            "     neutral       0.00      0.00      0.00        22\n",
            "    positive       0.58      0.69      0.63        55\n",
            "\n",
            "    accuracy                           0.48        96\n",
            "   macro avg       0.28      0.37      0.32        96\n",
            "weighted avg       0.39      0.48      0.43        96\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 8  0 11]\n",
            " [ 6  0 16]\n",
            " [16  1 38]]\n",
            "--------------------------------------------------\n",
            "Classification Report for 1980s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.39      0.26      0.31        88\n",
            "     neutral       0.33      0.02      0.04        43\n",
            "    positive       0.42      0.76      0.54        86\n",
            "\n",
            "    accuracy                           0.41       217\n",
            "   macro avg       0.38      0.35      0.30       217\n",
            "weighted avg       0.39      0.41      0.35       217\n",
            "\n",
            "Confusion Matrix:\n",
            "[[23  1 64]\n",
            " [16  1 26]\n",
            " [20  1 65]]\n",
            "--------------------------------------------------\n",
            "Classification Report for 1990s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.48      0.44      0.46        25\n",
            "     neutral       0.00      0.00      0.00        14\n",
            "    positive       0.21      0.46      0.29        13\n",
            "\n",
            "    accuracy                           0.33        52\n",
            "   macro avg       0.23      0.30      0.25        52\n",
            "weighted avg       0.28      0.33      0.29        52\n",
            "\n",
            "Confusion Matrix:\n",
            "[[11  0 14]\n",
            " [ 6  0  8]\n",
            " [ 6  1  6]]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LUPJE"
      ],
      "metadata": {
        "id": "uPGJ37I_73Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Read the text file into a DataFrame, skipping lines with incorrect formatting\n",
        "words_sentiment_df = pd.DataFrame(columns=[\"word\", \"sentiment_score\"])\n",
        "\n",
        "with open(\"LUPJE.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            word, sentiment_score = line.strip().split(\"\\t\")\n",
        "            words_sentiment_df = pd.concat([words_sentiment_df, pd.DataFrame({\"word\": [word], \"sentiment_score\": [sentiment_score]})])\n",
        "        except ValueError:\n",
        "            print(f\"Skipping line with incorrect formatting: {line.strip()}\")\n",
        "\n",
        "# Convert sentiment scores to numeric type\n",
        "words_sentiment_df[\"sentiment_score\"] = pd.to_numeric(words_sentiment_df[\"sentiment_score\"])\n",
        "\n",
        "# Function that performs the sentiment analysis\n",
        "def analyze_sentiment(text):\n",
        "    # Tokenize the text\n",
        "    tokens = text.split()\n",
        "    sentiment_score = 0\n",
        "\n",
        "    # Calculate sentiment score based on words in the text\n",
        "    for token in tokens:\n",
        "        if token in words_sentiment_df[\"word\"].values:\n",
        "            sentiment_score += words_sentiment_df.loc[words_sentiment_df[\"word\"] == token, \"sentiment_score\"].values[0]\n",
        "\n",
        "    # Determine sentiment label based on sentiment score\n",
        "    if sentiment_score > 0:\n",
        "        return \"positive\"\n",
        "    elif sentiment_score < 0:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "# Perform sentiment analysis on the dataset\n",
        "def perform_sentiment_analysis(dataset):\n",
        "    # Map numerical labels to sentiment categories\n",
        "    dataset[\"true_sentiment\"] = dataset[\"labels\"].map({0: \"negative\", 1: \"neutral\", 2: \"positive\"})\n",
        "\n",
        "    # Apply sentiment analysis to the text column\n",
        "    dataset[\"predicted_sentiment\"] = dataset[\"text\"].apply(analyze_sentiment)\n",
        "    return dataset\n",
        "\n",
        "# Function that performs sentiment analysis and generates a classification report for each dataset\n",
        "def generate_classification_report(dataset):\n",
        "    result_dataset = perform_sentiment_analysis(dataset)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(result_dataset[\"true_sentiment\"], result_dataset[\"predicted_sentiment\"])\n",
        "\n",
        "    return report\n",
        "\n",
        "# Paths to datasets\n",
        "dataset_paths = [\"1960s_gas.csv\", \"1970s_gas.csv\",\n",
        "                 \"1980s_gas.csv\", \"1990s_gas.csv\"]\n",
        "\n",
        "# Iterate over each dataset path in the list\n",
        "for dataset_path in dataset_paths:\n",
        "    dataset_name = dataset_path.split(\".\")[0]\n",
        "    your_dataset = pd.read_csv(dataset_path)\n",
        "    print(f\"Classification Report for {dataset_name}:\")\n",
        "    report = generate_classification_report(your_dataset)\n",
        "    print(report)\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPZX0siIIpU9",
        "outputId": "7be4b322-c02c-45e3-dc96-bea001620175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for 1960s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.20      0.30      0.25        82\n",
            "     neutral       0.43      0.07      0.12       131\n",
            "    positive       0.52      0.69      0.59       220\n",
            "\n",
            "    accuracy                           0.43       433\n",
            "   macro avg       0.38      0.35      0.32       433\n",
            "weighted avg       0.43      0.43      0.38       433\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for 1970s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.11      0.21      0.15        19\n",
            "     neutral       0.17      0.05      0.07        22\n",
            "    positive       0.50      0.49      0.50        55\n",
            "\n",
            "    accuracy                           0.33        96\n",
            "   macro avg       0.26      0.25      0.24        96\n",
            "weighted avg       0.35      0.33      0.33        96\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for 1980s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.44      0.40      0.42        88\n",
            "     neutral       0.27      0.07      0.11        43\n",
            "    positive       0.42      0.62      0.50        86\n",
            "\n",
            "    accuracy                           0.42       217\n",
            "   macro avg       0.38      0.36      0.34       217\n",
            "weighted avg       0.40      0.42      0.39       217\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for 1990s_gas:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.29      0.24      0.26        25\n",
            "     neutral       0.12      0.07      0.09        14\n",
            "    positive       0.13      0.23      0.17        13\n",
            "\n",
            "    accuracy                           0.19        52\n",
            "   macro avg       0.18      0.18      0.17        52\n",
            "weighted avg       0.20      0.19      0.19        52\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}