{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Traditional machine learning-based approaches"
      ],
      "metadata": {
        "id": "ENBIh1tyecEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "G-vt8EphefXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library that can handle class imbalance\n",
        "!pip install imbalanced-learn\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxXBVbmiqpa5",
        "outputId": "ed692984-9b6b-43dd-a505-5be12d4f3041"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Download NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Function to set all seeds for reproducibility\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# Setting the seed\n",
        "set_seed(42)\n",
        "\n",
        "# Function to load a single dataset\n",
        "def load_dataset(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "    return df['text'], df['labels']\n",
        "\n",
        "# Replace the numerical labels with the sentiment categories\n",
        "def map_labels(label):\n",
        "    if label == 0:\n",
        "        return \"negative\"\n",
        "    elif label == 1:\n",
        "        return \"neutral\"\n",
        "    elif label == 2:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# List of Dutch stop words\n",
        "dutch_stopwords = set(stopwords.words('dutch'))\n",
        "\n",
        "# Preprocess text data\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    tokens = [word for word in tokens if word not in dutch_stopwords]\n",
        "    # Join tokens back into a single string\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "# Function to perform sentiment analysis and generate a classification report and confusion matrix\n",
        "def cross_val_analysis(X_train_val, y_train_val, X_test, y_test):\n",
        "    tfidf = TfidfVectorizer()\n",
        "    X_train_val_tfidf = tfidf.fit_transform(X_train_val)\n",
        "    X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_train_val_tfidf, y_train_val)\n",
        "\n",
        "    nb_classifier = MultinomialNB()\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(nb_classifier, X_resampled, y_resampled, cv=skf)\n",
        "\n",
        "    # Cross-validation classification report and confusion matrix\n",
        "    report_cv = classification_report(y_resampled, y_pred_cv, zero_division=0)\n",
        "    cm_cv = confusion_matrix(y_resampled, y_pred_cv, labels=[\"negative\", \"neutral\", \"positive\"])\n",
        "\n",
        "    # Train final model on the entire training+validation set and test on the unseen test set\n",
        "    nb_classifier.fit(X_resampled, y_resampled)\n",
        "    y_pred_test = nb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "    # Test set classification report and confusion matrix\n",
        "    report_test = classification_report(y_test, y_pred_test, zero_division=0)\n",
        "    cm_test = confusion_matrix(y_test, y_pred_test, labels=[\"negative\", \"neutral\", \"positive\"])\n",
        "\n",
        "    return report_cv, cm_cv, report_test, cm_test\n",
        "\n",
        "# List of datasets paths\n",
        "dataset_paths = [\"1960s_gas.csv\", \"1970s_gas.csv\", \"1980s_gas.csv\", \"1990s_gas.csv\"]\n",
        "\n",
        "# Iterate over each dataset path in the list\n",
        "for dataset_path in dataset_paths:\n",
        "    dataset_name = dataset_path.split(\".\")[0]\n",
        "    print(f\"Processing {dataset_name}...\")\n",
        "\n",
        "    # Load dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # Preprocess the text data\n",
        "    X = X.apply(preprocess_text)\n",
        "\n",
        "    # Map numerical labels to sentiment categories for ground truth\n",
        "    y = y.apply(map_labels)\n",
        "\n",
        "    # Split the dataset into 85% training+validation and 15% test sets\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
        "\n",
        "    # Further split the training+validation set so that in the end there is a 70% training and 15% validation set\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # Combine training and validation sets for cross-validation\n",
        "    X_train_val_combined = pd.concat([X_train, X_val])\n",
        "    y_train_val_combined = pd.concat([y_train, y_val])\n",
        "\n",
        "    # Perform cross-validation analysis\n",
        "    report_cv, cm_cv, report_test, cm_test = cross_val_analysis(X_train_val_combined, y_train_val_combined, X_test, y_test)\n",
        "\n",
        "    # Print cross-validation classification report and confusion matrix\n",
        "    print(f\"Cross-Validation Classification Report for {dataset_name}:\\n\", report_cv)\n",
        "    print(f\"Cross-Validation Confusion Matrix for {dataset_name}:\\n\", cm_cv)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Print test set classification report and confusion matrix\n",
        "    print(f\"Test Set Classification Report for {dataset_name}:\\n\", report_test)\n",
        "    print(f\"Test Set Confusion Matrix for {dataset_name}:\\n\", cm_test)\n",
        "    print(\"=\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vHLFoNKdllO",
        "outputId": "e4975d18-6906-41ff-d27f-0e8e5b7c6b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1960s_gas...\n",
            "Cross-Validation Classification Report for 1960s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.93      0.86       187\n",
            "     neutral       0.78      0.73      0.75       187\n",
            "    positive       0.81      0.73      0.77       187\n",
            "\n",
            "    accuracy                           0.80       561\n",
            "   macro avg       0.80      0.80      0.79       561\n",
            "weighted avg       0.80      0.80      0.79       561\n",
            "\n",
            "Cross-Validation Confusion Matrix for 1960s_gas:\n",
            " [[174   9   4]\n",
            " [ 23 136  28]\n",
            " [ 22  29 136]]\n",
            "--------------------------------------------------\n",
            "Test Set Classification Report for 1960s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.32      0.50      0.39        12\n",
            "     neutral       0.33      0.25      0.29        20\n",
            "    positive       0.58      0.55      0.56        33\n",
            "\n",
            "    accuracy                           0.45        65\n",
            "   macro avg       0.41      0.43      0.41        65\n",
            "weighted avg       0.46      0.45      0.44        65\n",
            "\n",
            "Test Set Confusion Matrix for 1960s_gas:\n",
            " [[ 6  4  2]\n",
            " [ 4  5 11]\n",
            " [ 9  6 18]]\n",
            "==================================================\n",
            "Processing 1970s_gas...\n",
            "Cross-Validation Classification Report for 1970s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.96      0.83        46\n",
            "     neutral       0.76      0.89      0.82        46\n",
            "    positive       0.83      0.43      0.57        46\n",
            "\n",
            "    accuracy                           0.76       138\n",
            "   macro avg       0.78      0.76      0.74       138\n",
            "weighted avg       0.78      0.76      0.74       138\n",
            "\n",
            "Cross-Validation Confusion Matrix for 1970s_gas:\n",
            " [[44  0  2]\n",
            " [ 3 41  2]\n",
            " [13 13 20]]\n",
            "--------------------------------------------------\n",
            "Test Set Classification Report for 1970s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.43      1.00      0.60         3\n",
            "     neutral       0.00      0.00      0.00         3\n",
            "    positive       0.57      0.44      0.50         9\n",
            "\n",
            "    accuracy                           0.47        15\n",
            "   macro avg       0.33      0.48      0.37        15\n",
            "weighted avg       0.43      0.47      0.42        15\n",
            "\n",
            "Test Set Confusion Matrix for 1970s_gas:\n",
            " [[3 0 0]\n",
            " [0 0 3]\n",
            " [4 1 4]]\n",
            "==================================================\n",
            "Processing 1980s_gas...\n",
            "Cross-Validation Classification Report for 1980s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.53      0.55      0.54        75\n",
            "     neutral       0.71      0.81      0.76        75\n",
            "    positive       0.56      0.45      0.50        75\n",
            "\n",
            "    accuracy                           0.60       225\n",
            "   macro avg       0.60      0.60      0.60       225\n",
            "weighted avg       0.60      0.60      0.60       225\n",
            "\n",
            "Cross-Validation Confusion Matrix for 1980s_gas:\n",
            " [[41 11 23]\n",
            " [10 61  4]\n",
            " [27 14 34]]\n",
            "--------------------------------------------------\n",
            "Test Set Classification Report for 1980s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.50      0.46      0.48        13\n",
            "     neutral       0.43      0.43      0.43         7\n",
            "    positive       0.36      0.38      0.37        13\n",
            "\n",
            "    accuracy                           0.42        33\n",
            "   macro avg       0.43      0.42      0.43        33\n",
            "weighted avg       0.43      0.42      0.43        33\n",
            "\n",
            "Test Set Confusion Matrix for 1980s_gas:\n",
            " [[6 2 5]\n",
            " [0 3 4]\n",
            " [6 2 5]]\n",
            "==================================================\n",
            "Processing 1990s_gas...\n",
            "Cross-Validation Classification Report for 1990s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.71      0.24      0.36        21\n",
            "     neutral       0.67      0.95      0.78        21\n",
            "    positive       0.65      0.81      0.72        21\n",
            "\n",
            "    accuracy                           0.67        63\n",
            "   macro avg       0.68      0.67      0.62        63\n",
            "weighted avg       0.68      0.67      0.62        63\n",
            "\n",
            "Cross-Validation Confusion Matrix for 1990s_gas:\n",
            " [[ 5  8  8]\n",
            " [ 0 20  1]\n",
            " [ 2  2 17]]\n",
            "--------------------------------------------------\n",
            "Test Set Classification Report for 1990s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.33      0.25      0.29         4\n",
            "     neutral       0.33      0.50      0.40         2\n",
            "    positive       0.50      0.50      0.50         2\n",
            "\n",
            "    accuracy                           0.38         8\n",
            "   macro avg       0.39      0.42      0.40         8\n",
            "weighted avg       0.38      0.38      0.37         8\n",
            "\n",
            "Test Set Confusion Matrix for 1990s_gas:\n",
            " [[1 2 1]\n",
            " [1 1 0]\n",
            " [1 0 1]]\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine"
      ],
      "metadata": {
        "id": "lyrFsftMelSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library that can handle class imbalance\n",
        "!pip install scikit-learn imbalanced-learn\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGQxLELKzTQQ",
        "outputId": "cfb418e8-c25e-4c38-c798-bf752c521622"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import nltk\n",
        "\n",
        "# Download NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Function to set all seeds for reproducibility\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# Setting the seed\n",
        "set_seed(42)\n",
        "\n",
        "# Function to load a single dataset\n",
        "def load_dataset(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "    return df['text'], df['labels']\n",
        "\n",
        "# Replace the numerical labels with the sentiment categories\n",
        "def map_labels(label):\n",
        "    if label == 0:\n",
        "        return \"negative\"\n",
        "    elif label == 1:\n",
        "        return \"neutral\"\n",
        "    elif label == 2:\n",
        "        return \"positive\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# List of Dutch stop words\n",
        "dutch_stopwords = set(stopwords.words('dutch'))\n",
        "\n",
        "# Preprocess text data\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    tokens = [word for word in tokens if word not in dutch_stopwords]\n",
        "    # Join tokens back into a single string\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "# Function to perform sentiment analysis and generate classification report and confusion matrix\n",
        "def cross_val_analysis(X_train_val, y_train_val, X_test, y_test):\n",
        "    tfidf = TfidfVectorizer()\n",
        "    X_train_val_tfidf = tfidf.fit_transform(X_train_val)\n",
        "    X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_train_val_tfidf, y_train_val)\n",
        "\n",
        "    svm_classifier = SVC(kernel='linear', random_state=42)  # Using linear kernel as an example, you can change it\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    y_pred_cv = cross_val_predict(svm_classifier, X_resampled, y_resampled, cv=skf)\n",
        "\n",
        "    # Cross-validation classification report and confusion matrix\n",
        "    report_cv = classification_report(y_resampled, y_pred_cv, zero_division=0)\n",
        "    cm_cv = confusion_matrix(y_resampled, y_pred_cv, labels=[\"negative\", \"neutral\", \"positive\"])\n",
        "\n",
        "    # Train final model on the entire training+validation set and test on the unseen test set\n",
        "    svm_classifier.fit(X_resampled, y_resampled)\n",
        "    y_pred_test = svm_classifier.predict(X_test_tfidf)\n",
        "\n",
        "    # Test set classification report and confusion matrix\n",
        "    report_test = classification_report(y_test, y_pred_test, zero_division=0)\n",
        "    cm_test = confusion_matrix(y_test, y_pred_test, labels=[\"negative\", \"neutral\", \"positive\"])\n",
        "\n",
        "    return report_cv, cm_cv, report_test, cm_test\n",
        "\n",
        "# List of datasets paths\n",
        "dataset_paths = [\"1960s_gas.csv\", \"1970s_gas.csv\", \"1980s_gas.csv\", \"1990s_gas.csv\"]\n",
        "\n",
        "# Iterate over each dataset path in the list\n",
        "for dataset_path in dataset_paths:\n",
        "    dataset_name = dataset_path.split(\".\")[0]\n",
        "    print(f\"Processing {dataset_name}...\")\n",
        "\n",
        "    # Load dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # Preprocess the text data\n",
        "    X = X.apply(preprocess_text)\n",
        "\n",
        "    # Map numerical labels to sentiment categories for ground truth\n",
        "    y = y.apply(map_labels)\n",
        "\n",
        "    # Split the dataset into 85% training+validation and 15% test sets\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
        "\n",
        "    # Further split the training+validation set so that in the end there is 70% training and 15% validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # Combine training and validation sets for cross-validation\n",
        "    X_train_val_combined = pd.concat([X_train, X_val])\n",
        "    y_train_val_combined = pd.concat([y_train, y_val])\n",
        "\n",
        "    # Perform cross-validation analysis\n",
        "    report_cv, cm_cv, report_test, cm_test = cross_val_analysis(X_train_val_combined, y_train_val_combined, X_test, y_test)\n",
        "\n",
        "    # Print cross-validation classification report and confusion matrix\n",
        "    print(f\"Cross-Validation Classification Report for {dataset_name}:\\n\", report_cv)\n",
        "    print(f\"Cross-Validation Confusion Matrix for {dataset_name}:\\n\", cm_cv)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Print test set classification report and confusion matrix\n",
        "    print(f\"Test Set Classification Report for {dataset_name}:\\n\", report_test)\n",
        "    print(f\"Test Set Confusion Matrix for {dataset_name}:\\n\", cm_test)\n",
        "    print(\"=\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zXDfdJcj9A6",
        "outputId": "3cc23742-d68d-4beb-c52a-ded41f21fcb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1960s_gas...\n",
            "Cross-Validation Classification Report for 1960s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.91      0.92      0.92       187\n",
            "     neutral       0.81      0.78      0.79       187\n",
            "    positive       0.76      0.78      0.77       187\n",
            "\n",
            "    accuracy                           0.83       561\n",
            "   macro avg       0.83      0.83      0.83       561\n",
            "weighted avg       0.83      0.83      0.83       561\n",
            "\n",
            "Cross-Validation Confusion Matrix for 1960s_gas:\n",
            " [[172   5  10]\n",
            " [  5 145  37]\n",
            " [ 11  30 146]]\n",
            "--------------------------------------------------\n",
            "Test Set Classification Report for 1960s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.30      0.25      0.27        12\n",
            "     neutral       0.31      0.20      0.24        20\n",
            "    positive       0.55      0.70      0.61        33\n",
            "\n",
            "    accuracy                           0.46        65\n",
            "   macro avg       0.39      0.38      0.38        65\n",
            "weighted avg       0.43      0.46      0.44        65\n",
            "\n",
            "Test Set Confusion Matrix for 1960s_gas:\n",
            " [[ 3  3  6]\n",
            " [ 3  4 13]\n",
            " [ 4  6 23]]\n",
            "==================================================\n",
            "Processing 1970s_gas...\n",
            "Cross-Validation Classification Report for 1970s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.98      0.91      0.94        46\n",
            "     neutral       0.95      0.87      0.91        46\n",
            "    positive       0.81      0.93      0.87        46\n",
            "\n",
            "    accuracy                           0.91       138\n",
            "   macro avg       0.91      0.91      0.91       138\n",
            "weighted avg       0.91      0.91      0.91       138\n",
            "\n",
            "Cross-Validation Confusion Matrix for 1970s_gas:\n",
            " [[42  0  4]\n",
            " [ 0 40  6]\n",
            " [ 1  2 43]]\n",
            "--------------------------------------------------\n",
            "Test Set Classification Report for 1970s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.33      0.50         3\n",
            "     neutral       0.00      0.00      0.00         3\n",
            "    positive       0.64      1.00      0.78         9\n",
            "\n",
            "    accuracy                           0.67        15\n",
            "   macro avg       0.55      0.44      0.43        15\n",
            "weighted avg       0.59      0.67      0.57        15\n",
            "\n",
            "Test Set Confusion Matrix for 1970s_gas:\n",
            " [[1 0 2]\n",
            " [0 0 3]\n",
            " [0 0 9]]\n",
            "==================================================\n",
            "Processing 1980s_gas...\n",
            "Cross-Validation Classification Report for 1980s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.52      0.53      0.53        75\n",
            "     neutral       0.89      0.79      0.84        75\n",
            "    positive       0.54      0.59      0.56        75\n",
            "\n",
            "    accuracy                           0.64       225\n",
            "   macro avg       0.65      0.64      0.64       225\n",
            "weighted avg       0.65      0.64      0.64       225\n",
            "\n",
            "Cross-Validation Confusion Matrix for 1980s_gas:\n",
            " [[40  3 32]\n",
            " [10 59  6]\n",
            " [27  4 44]]\n",
            "--------------------------------------------------\n",
            "Test Set Classification Report for 1980s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.60      0.46      0.52        13\n",
            "     neutral       0.00      0.00      0.00         7\n",
            "    positive       0.36      0.62      0.46        13\n",
            "\n",
            "    accuracy                           0.42        33\n",
            "   macro avg       0.32      0.36      0.33        33\n",
            "weighted avg       0.38      0.42      0.39        33\n",
            "\n",
            "Test Set Confusion Matrix for 1980s_gas:\n",
            " [[6 0 7]\n",
            " [0 0 7]\n",
            " [4 1 8]]\n",
            "==================================================\n",
            "Processing 1990s_gas...\n",
            "Cross-Validation Classification Report for 1990s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.65      0.95      0.77        21\n",
            "     neutral       0.94      0.76      0.84        21\n",
            "    positive       0.93      0.67      0.78        21\n",
            "\n",
            "    accuracy                           0.79        63\n",
            "   macro avg       0.84      0.79      0.80        63\n",
            "weighted avg       0.84      0.79      0.80        63\n",
            "\n",
            "Cross-Validation Confusion Matrix for 1990s_gas:\n",
            " [[20  0  1]\n",
            " [ 5 16  0]\n",
            " [ 6  1 14]]\n",
            "--------------------------------------------------\n",
            "Test Set Classification Report for 1990s_gas:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.50      0.75      0.60         4\n",
            "     neutral       0.00      0.00      0.00         2\n",
            "    positive       0.50      0.50      0.50         2\n",
            "\n",
            "    accuracy                           0.50         8\n",
            "   macro avg       0.33      0.42      0.37         8\n",
            "weighted avg       0.38      0.50      0.42         8\n",
            "\n",
            "Test Set Confusion Matrix for 1990s_gas:\n",
            " [[3 0 1]\n",
            " [2 0 0]\n",
            " [1 0 1]]\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}